{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos ya forma parte de la biblioteca Scikit-Learn, sÃ³lo tenemos que importarlo y cargarlo como un marco de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\programdata\\anaconda3\\lib\\site-packages (1.3.4)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2021.3)\n",
      "Requirement already satisfied: python-dateutil>=2.7.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas) (1.20.3)\n",
      "Requirement already satisfied: six>=1.5 in c:\\programdata\\anaconda3\\lib\\site-packages (from python-dateutil>=2.7.3->pandas) (1.16.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: scikit-learn in c:\\programdata\\anaconda3\\lib\\site-packages (0.24.2)\n",
      "Collecting scikit-learn\n",
      "  Using cached scikit_learn-1.3.0-cp39-cp39-win_amd64.whl (9.3 MB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.20.3)\n",
      "Collecting joblib>=1.1.1\n",
      "  Using cached joblib-1.3.2-py3-none-any.whl (302 kB)\n",
      "Requirement already satisfied: scipy>=1.5.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (1.7.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from scikit-learn) (2.2.0)\n",
      "Installing collected packages: joblib, scikit-learn\n",
      "  Attempting uninstall: joblib\n",
      "    Found existing installation: joblib 1.1.0\n",
      "    Uninstalling joblib-1.1.0:\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "    WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "ERROR: Could not install packages due to an OSError: [WinError 5] Acceso denegado: 'c:\\\\programdata\\\\anaconda3\\\\lib\\\\site-packages\\\\joblib-1.1.0.dist-info\\\\direct_url.json'\n",
      "Consider using the `--user` option or check the permissions.\n",
      "\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: seaborn in c:\\programdata\\anaconda3\\lib\\site-packages (0.11.2)\n",
      "Requirement already satisfied: numpy>=1.15 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.20.3)\n",
      "Requirement already satisfied: matplotlib>=2.2 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (3.4.3)\n",
      "Requirement already satisfied: scipy>=1.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.7.1)\n",
      "Requirement already satisfied: pandas>=0.23 in c:\\programdata\\anaconda3\\lib\\site-packages (from seaborn) (1.3.4)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (2.8.2)\n",
      "Requirement already satisfied: cycler>=0.10 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pyparsing>=2.2.1 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (3.0.4)\n",
      "Requirement already satisfied: pillow>=6.2.0 in c:\\programdata\\anaconda3\\lib\\site-packages (from matplotlib>=2.2->seaborn) (8.4.0)\n",
      "Requirement already satisfied: six in c:\\programdata\\anaconda3\\lib\\site-packages (from cycler>=0.10->matplotlib>=2.2->seaborn) (1.16.0)\n",
      "Requirement already satisfied: pytz>=2017.3 in c:\\programdata\\anaconda3\\lib\\site-packages (from pandas>=0.23->seaborn) (2021.3)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution -oblib (c:\\programdata\\anaconda3\\lib\\site-packages)\n",
      "WARNING: Ignoring invalid distribution - (c:\\programdata\\anaconda3\\lib\\site-packages)\n"
     ]
    }
   ],
   "source": [
    "pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sepal_length</th>\n",
       "      <th>sepal_width</th>\n",
       "      <th>petal_length</th>\n",
       "      <th>petal_width</th>\n",
       "      <th>species</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>5.8</td>\n",
       "      <td>2.8</td>\n",
       "      <td>5.1</td>\n",
       "      <td>2.4</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>6.0</td>\n",
       "      <td>2.2</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>versicolor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>5.5</td>\n",
       "      <td>4.2</td>\n",
       "      <td>1.4</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>7.3</td>\n",
       "      <td>2.9</td>\n",
       "      <td>6.3</td>\n",
       "      <td>1.8</td>\n",
       "      <td>virginica</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>5.0</td>\n",
       "      <td>3.4</td>\n",
       "      <td>1.5</td>\n",
       "      <td>0.2</td>\n",
       "      <td>setosa</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     sepal_length  sepal_width  petal_length  petal_width     species\n",
       "114           5.8          2.8           5.1          2.4   virginica\n",
       "62            6.0          2.2           4.0          1.0  versicolor\n",
       "33            5.5          4.2           1.4          0.2      setosa\n",
       "107           7.3          2.9           6.3          1.8   virginica\n",
       "7             5.0          3.4           1.5          0.2      setosa"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.datasets import fetch_california_housing\n",
    "from sklearn import datasets\n",
    "import seaborn as sns\n",
    "\n",
    "iris = sns.load_dataset(\"iris\")\n",
    "iris.sample(5, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method NDFrame.head of      sepal_length  sepal_width  petal_length  petal_width    species\n",
       "0             5.1          3.5           1.4          0.2     setosa\n",
       "1             4.9          3.0           1.4          0.2     setosa\n",
       "2             4.7          3.2           1.3          0.2     setosa\n",
       "3             4.6          3.1           1.5          0.2     setosa\n",
       "4             5.0          3.6           1.4          0.2     setosa\n",
       "..            ...          ...           ...          ...        ...\n",
       "145           6.7          3.0           5.2          2.3  virginica\n",
       "146           6.3          2.5           5.0          1.9  virginica\n",
       "147           6.5          3.0           5.2          2.0  virginica\n",
       "148           6.2          3.4           5.4          2.3  virginica\n",
       "149           5.9          3.0           5.1          1.8  virginica\n",
       "\n",
       "[150 rows x 5 columns]>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "iris.head"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "iris.drop('species', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 4 columns):\n",
      " #   Column        Non-Null Count  Dtype  \n",
      "---  ------        --------------  -----  \n",
      " 0   sepal_length  150 non-null    float64\n",
      " 1   sepal_width   150 non-null    float64\n",
      " 2   petal_length  150 non-null    float64\n",
      " 3   petal_width   150 non-null    float64\n",
      "dtypes: float64(4)\n",
      "memory usage: 4.8 KB\n"
     ]
    }
   ],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El conjunto de datos consta de nueve atributos:\n",
    "\n",
    "- MedInc - renta mediana en un grupo de bloques\n",
    "- HouseAge - edad media de la vivienda en un grupo de bloques\n",
    "- AveRooms - nÃºmero medio de habitaciones (proporcionadas por hogar)\n",
    "- AveBedrms - nÃºmero medio de dormitorios (por hogar)\n",
    "- Population - poblaciÃ³n del grupo de bloques\n",
    "- AveOccup - nÃºmero medio de miembros del hogar\n",
    "- Latitud - latitud del grupo de bloques\n",
    "- Longitud - longitud del grupo de bloques\n",
    "- MedHouseVal - valor medio de la vivienda en los distritos de California (cientos de miles de dÃ³lares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " En esta tarea, en lugar de predecir un valor continuo, queremos predecir la clase a la que pertenecen estos grupos de bloques. Para ello, podemos dividir la mediana del valor de la vivienda de los distritos en grupos con distintos rangos o intervalos de valores de la vivienda. Cuando se desea utilizar un valor continuo para la clasificaciÃ³n, normalmente se pueden agrupar los datos. De este modo, puedes predecir grupos, en lugar de valores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      5\n",
       "1      2\n",
       "2      4\n",
       "3      3\n",
       "4      5\n",
       "      ..\n",
       "145    2\n",
       "146    1\n",
       "147    2\n",
       "148    4\n",
       "149    2\n",
       "Name: sepal_width_S, Length: 150, dtype: category\n",
       "Categories (5, int64): [1 < 2 < 3 < 4 < 5]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Vamos a crear los bins de datos para transformar nuestros valores continuos en categorÃ­as:\n",
    "iris[\"sepal_width_S\"] = pd.qcut(iris[\"sepal_width\"], 5, retbins=False, labels=[1, 2, 3, 4, 5])\n",
    "iris[\"sepal_width_S\"]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# A continuaciÃ³n, podemos dividir nuestro conjunto de datos en sus atributos y etiquetas:\n",
    "y = iris['sepal_width_S']\n",
    "X = iris.drop(['sepal_width', 'sepal_width_S'], axis = 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Como hemos utilizado la columna MedHouseVal para crear bins, tenemos que eliminar las columnas MedHouseVal y MedHouseValCat de X. De esta forma, el DataFrame contendrÃ¡ las 8 primeras columnas del conjunto de datos (es decir, atributos, caracterÃ­sticas) mientras que nuestra y contendrÃ¡ sÃ³lo la etiqueta asignada MedHouseValCat."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dividir los datos en conjuntos de entrenamiento y de prueba"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Utilizaremos de nuevo el valor estÃ¡ndar de Scikit-Learn de 75% de datos de entrenamiento y 25% de datos de prueba. Esto significa que tendremos el mismo nÃºmero de registros de entrenamiento y de prueba que en la regresiÃ³n anterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 150 entries, 0 to 149\n",
      "Data columns (total 5 columns):\n",
      " #   Column         Non-Null Count  Dtype   \n",
      "---  ------         --------------  -----   \n",
      " 0   sepal_length   150 non-null    float64 \n",
      " 1   sepal_width    150 non-null    float64 \n",
      " 2   petal_length   150 non-null    float64 \n",
      " 3   petal_width    150 non-null    float64 \n",
      " 4   sepal_width_S  150 non-null    category\n",
      "dtypes: category(1), float64(4)\n",
      "memory usage: 5.2 KB\n"
     ]
    }
   ],
   "source": [
    "iris.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "SEED = 42\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dado que estamos tratando con el mismo conjunto de datos sin procesar y sus diferentes unidades de medida, realizaremos de nuevo el escalado de caracterÃ­sticas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escalado de caracterÃ­sticas para la clasificaciÃ³n\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "scaler.fit(X_train)\n",
    "\n",
    "X_train = scaler.transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-1.01827123, -1.39338902, -1.3621769 ],\n",
       "       [-0.7730102 , -1.33550342, -1.49647603],\n",
       "       [-0.03722712,  0.74837808,  0.92090833],\n",
       "       [ 0.20803391,  0.4010645 ,  0.51801093],\n",
       "       [ 1.06644751,  0.51683569,  0.3837118 ],\n",
       "       [-0.52774918, -1.45127462, -1.09357864],\n",
       "       [-0.52774918, -1.33550342, -1.3621769 ],\n",
       "       [-0.40511866, -0.06202028, -0.28778385],\n",
       "       [ 0.57592545,  0.74837808,  0.3837118 ],\n",
       "       [ 0.69855596,  0.97992047,  0.7866092 ],\n",
       "       [ 0.94381699,  0.3431789 ,  0.24941267],\n",
       "       [ 1.67960008,  1.32723405,  1.72670311],\n",
       "       [-0.15985763,  0.2274077 ,  0.11511354],\n",
       "       [ 2.17012213,  1.61666204,  1.18950659],\n",
       "       [-0.28248815,  0.4010645 ,  0.3837118 ],\n",
       "       [-0.89564072, -1.39338902, -1.3621769 ],\n",
       "       [ 2.29275265,  1.67454764,  1.05520746],\n",
       "       [-0.03722712,  0.16952211, -0.28778385],\n",
       "       [-0.7730102 , -1.39338902, -1.3621769 ],\n",
       "       [-1.01827123, -1.45127462, -1.22787777],\n",
       "       [-0.89564072, -1.10396103, -1.09357864],\n",
       "       [-1.01827123, -0.17779148, -0.28778385],\n",
       "       [ 0.57592545,  0.63260689,  0.7866092 ],\n",
       "       [-1.26353226, -1.10396103, -1.3621769 ],\n",
       "       [-1.01827123, -1.27761783, -1.3621769 ],\n",
       "       [-0.89564072, -1.21973223, -0.95927951],\n",
       "       [-0.28248815,  0.2274077 ,  0.11511354],\n",
       "       [-0.89564072, -1.33550342, -1.3621769 ],\n",
       "       [-0.15985763,  0.2274077 , -0.01918559],\n",
       "       [ 2.29275265,  1.67454764,  1.32380572],\n",
       "       [-1.50879329, -1.39338902, -1.3621769 ],\n",
       "       [ 0.45329494,  0.2852933 ,  0.11511354],\n",
       "       [-0.15985763,  0.69049248,  1.05520746],\n",
       "       [-0.40511866, -1.39338902, -1.3621769 ],\n",
       "       [ 0.20803391,  0.57472129,  0.7866092 ],\n",
       "       [-0.03722712,  0.74837808,  0.92090833],\n",
       "       [ 0.20803391,  0.11163651, -0.28778385],\n",
       "       [-0.52774918,  0.4010645 ,  0.3837118 ],\n",
       "       [ 0.45329494,  0.92203487,  1.45810485],\n",
       "       [-0.40511866,  0.11163651,  0.11511354],\n",
       "       [-0.52774918, -1.21973223, -1.09357864],\n",
       "       [-1.01827123, -0.29356267, -0.28778385],\n",
       "       [ 0.69855596,  0.86414927,  0.92090833],\n",
       "       [-1.01827123, -1.39338902, -1.3621769 ],\n",
       "       [-1.01827123, -1.50916022, -1.3621769 ],\n",
       "       [-0.40511866, -0.00413469, -0.15348472],\n",
       "       [ 1.06644751,  0.69049248,  0.65231006],\n",
       "       [-1.14090175, -1.33550342, -1.3621769 ],\n",
       "       [-0.03722712,  0.74837808,  1.59240398],\n",
       "       [-1.01827123, -1.33550342, -1.3621769 ],\n",
       "       [-1.01827123, -1.27761783, -0.82498038],\n",
       "       [ 0.08540339,  0.57472129,  0.7866092 ],\n",
       "       [-0.89564072, -0.46721946, -0.15348472],\n",
       "       [ 1.31170853,  1.09569166,  1.45810485],\n",
       "       [ 0.20803391,  0.74837808,  0.51801093],\n",
       "       [ 0.33066442,  1.03780607,  0.24941267],\n",
       "       [ 2.29275265,  1.32723405,  1.45810485],\n",
       "       [-0.40511866,  0.11163651,  0.11511354],\n",
       "       [-1.75405432, -1.39338902, -1.3621769 ],\n",
       "       [-1.87668483, -1.56704581, -1.49647603],\n",
       "       [ 0.20803391,  0.69049248,  0.3837118 ],\n",
       "       [ 1.67960008,  1.26934846,  0.7866092 ],\n",
       "       [-1.50879329, -1.33550342, -1.3621769 ],\n",
       "       [-0.89564072, -1.39338902, -1.22787777],\n",
       "       [-1.75405432, -1.45127462, -1.3621769 ],\n",
       "       [ 0.57592545,  0.63260689,  0.3837118 ],\n",
       "       [ 0.57592545,  1.03780607,  1.59240398],\n",
       "       [-1.50879329, -1.39338902, -1.22787777],\n",
       "       [ 1.18907802,  0.97992047,  1.18950659],\n",
       "       [ 0.57592545,  1.26934846,  1.72670311],\n",
       "       [-1.38616278, -1.45127462, -1.3621769 ],\n",
       "       [ 0.33066442,  0.51683569,  0.24941267],\n",
       "       [ 0.82118648,  0.45895009,  0.3837118 ],\n",
       "       [ 0.45329494,  0.57472129,  0.7866092 ],\n",
       "       [ 1.43433905,  0.51683569,  0.24941267],\n",
       "       [ 0.69855596,  0.86414927,  1.45810485],\n",
       "       [-0.89564072, -1.27761783, -1.3621769 ],\n",
       "       [ 1.31170853,  0.92203487,  1.18950659],\n",
       "       [ 0.08540339,  0.2274077 ,  0.3837118 ],\n",
       "       [ 0.82118648,  0.80626368,  1.05520746],\n",
       "       [-0.15985763, -0.17779148, -0.28778385],\n",
       "       [-0.7730102 ,  0.05375091,  0.24941267],\n",
       "       [ 0.33066442,  0.45895009,  0.24941267],\n",
       "       [-1.6314238 , -1.45127462, -1.22787777],\n",
       "       [ 0.94381699,  0.45895009,  0.11511354],\n",
       "       [-0.40511866,  0.3431789 , -0.01918559],\n",
       "       [-0.65037969, -1.33550342, -1.3621769 ],\n",
       "       [-0.28248815,  0.16952211,  0.11511354],\n",
       "       [ 1.80223059,  1.44300525,  0.7866092 ],\n",
       "       [ 1.06644751,  1.09569166,  1.18950659],\n",
       "       [-0.89564072, -1.33550342, -1.09357864],\n",
       "       [-1.14090175, -0.29356267, -0.28778385],\n",
       "       [ 1.06644751,  1.09569166,  1.72670311],\n",
       "       [ 1.67960008,  1.15357726,  0.51801093],\n",
       "       [-1.14090175, -1.39338902, -1.49647603],\n",
       "       [ 1.06644751,  1.03780607,  1.59240398],\n",
       "       [-1.14090175, -1.39338902, -1.3621769 ],\n",
       "       [ 1.31170853,  0.63260689,  0.3837118 ],\n",
       "       [ 1.9248611 ,  1.32723405,  0.92090833],\n",
       "       [ 0.57592545,  1.03780607,  0.7866092 ],\n",
       "       [-0.15985763,  0.16952211,  0.11511354],\n",
       "       [ 0.82118648,  0.97992047,  0.7866092 ],\n",
       "       [ 0.57592545,  0.3431789 ,  0.11511354],\n",
       "       [ 0.69855596,  0.2852933 ,  0.11511354],\n",
       "       [-0.28248815,  0.63260689,  1.05520746],\n",
       "       [ 0.08540339,  0.74837808,  0.7866092 ],\n",
       "       [-0.52774918, -1.21973223, -1.3621769 ],\n",
       "       [ 0.33066442,  0.11163651,  0.11511354],\n",
       "       [-1.14090175,  0.4010645 ,  0.65231006],\n",
       "       [-0.03722712, -1.50916022, -1.3621769 ],\n",
       "       [-0.03722712,  0.11163651, -0.01918559],\n",
       "       [ 1.55696956,  1.21146286,  1.18950659]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Entrenamiento y predicciÃ³n para la clasificaciÃ³n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "DespuÃ©s de agrupar, dividir y escalar los datos, podemos aplicarles un clasificador. Para la predicciÃ³n, utilizaremos de nuevo 5 vecinos como lÃ­nea de base. TambiÃ©n puede instanciar la clase KNeighbors_ sin ningÃºn argumento y automÃ¡ticamente utilizarÃ¡ 5 vecinos. AquÃ­, en lugar de importar el KNeighborsRegressor, importaremos el KNeighborsClassifier, clase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KNeighborsClassifier()"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "\n",
    "classifier = KNeighborsClassifier()\n",
    "classifier.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tras ajustar el KNeighborsClassifier, podemos predecir las clases de los datos de prueba:\n",
    "y_pred = classifier.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Evaluando KNN para la clasificaciÃ³n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para evaluar el clasificador KNN, tambiÃ©n podemos utilizar el mÃ©todo de puntuaciÃ³n, pero ejecuta una mÃ©trica diferente ya que estamos puntuando un clasificador y no un regresor. La mÃ©trica bÃ¡sica para la clasificaciÃ³n es la precisiÃ³n, que describe cuÃ¡ntas predicciones acertÃ³ nuestro clasificador. El valor de precisiÃ³n mÃ¡s bajo es 0 y el mÃ¡s alto es 1. Normalmente multiplicamos ese valor por 100 para obtener un porcentaje.\n",
    "\n",
    "$$accuracy=\\frac{number of correct predictions\n",
    "}{total number of predictions\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.42105263157894735\n"
     ]
    }
   ],
   "source": [
    "acc =  classifier.score(X_test, y_test)\n",
    "print(acc) # 0.6191860465116279"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observando la puntuaciÃ³n resultante, podemos deducir que nuestro clasificador acertÃ³ en ~62% de las clases. Esto ya ayuda en el anÃ¡lisis, aunque al saber solo lo que el clasificador acertÃ³, es difÃ­cil mejorarlo."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tanto un fallo sistÃ©mico de alguna clase como un fallo compartido entre clases pueden arrojar una puntuaciÃ³n de precisiÃ³n del 62%. La precisiÃ³n no es una buena mÃ©trica para la evaluaciÃ³n real, pero sirve como una buena aproximaciÃ³n. En la mayorÃ­a de los casos, con conjuntos de datos equilibrados, una precisiÃ³n del 62% estÃ¡ relativamente repartida. AdemÃ¡s, en la mayorÃ­a de los casos, los conjuntos de datos no estÃ¡n equilibrados, por lo que volvemos a la casilla de salida, ya que la precisiÃ³n es una mÃ©trica insuficiente.\n",
    "\n",
    "Podemos profundizar en los resultados utilizando otras mÃ©tricas para poder determinarlo. Este paso tambiÃ©n es diferente de la regresiÃ³n, aquÃ­ vamos a utilizar:\n",
    "\n",
    "1. **Matriz de la confusiÃ³n**: Para saber cuÃ¡nto acertamos o nos equivocamos en cada clase. Los valores que fueron correctos y se predijeron correctamente se denominan verdaderos positivos los que se predijeron como positivos pero no lo fueron se denominan falsos positivos. La misma nomenclatura de verdaderos negativos y falsos negativos se utiliza para los valores negativos;\n",
    "2. **PrecisiÃ³n**: Para saber quÃ© valores de predicciÃ³n fueron considerados correctos por nuestro clasificador. La precisiÃ³n dividirÃ¡ esos valores de verdaderos positivos entre todo lo que se predijo como positivo; \n",
    "$$precision=\\frac{truepositive}{true positive + false positive}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "3. **Recall**: para saber cuÃ¡ntos de los verdaderos positivos fueron identificados por nuestro clasificador. La recuperaciÃ³n se calcula dividiendo los verdaderos positivos por todo lo que deberÃ­a haberse predicho como positivo.\n",
    "$$Recall=\\frac{truepositive}{true positive + false negative}."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**F1 Score**: Es la media equilibrada o armÃ³nica de precisiÃ³n y recall. El valor mÃ¡s bajo es 0 y el mÃ¡s alto es 1. Cuando la puntuaciÃ³n f1 es igual a 1, significa que todas las clases se predijeron correctamente; se trata de una puntuaciÃ³n muy difÃ­cil de obtener con datos reales (casi siempre hay excepciones).\n",
    "$$f1-score=\\frac{precisioin * recall}{precisioin + recall}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los mÃ©todos confusion_matrix() y classification_report() del mÃ³dulo sklearn.metrics pueden utilizarse para calcular y mostrar todas estas mÃ©tricas. La matriz de confusiÃ³n se visualiza mejor utilizando un mapa de calor. El informe de clasificaciÃ³n ya nos proporciona exactitud, precisiÃ³n, recall y f1-score, pero tambiÃ©n puedes importar cada una de estas mÃ©tricas desde sklearn.metrics.\n",
    "\n",
    "Para obtener las mÃ©tricas, ejecute el siguiente fragmento:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           1       0.50      0.33      0.40         6\n",
      "           2       0.33      0.42      0.37        12\n",
      "           3       0.50      0.25      0.33         4\n",
      "           4       0.30      0.33      0.32         9\n",
      "           5       0.71      0.71      0.71         7\n",
      "\n",
      "    accuracy                           0.42        38\n",
      "   macro avg       0.47      0.41      0.43        38\n",
      "weighted avg       0.44      0.42      0.42        38\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "#importing Seaborn's to use the heatmap \n",
    "import seaborn as sns\n",
    "\n",
    "# Adding classes names for better interpretation\n",
    "classes_names = ['class 1','class 2','class 3', 'class 4','class 5']\n",
    "cm = pd.DataFrame(confusion_matrix(y_test, y_pred), \n",
    "                  columns=classes_names, index = classes_names)\n",
    "                  \n",
    "# Seaborn's heatmap to better visualize the confusion matrix\n",
    "sns.heatmap(cm, annot=True, fmt='d');\n",
    "\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los resultados muestran que KNN fue capaz de clasificar los 5160 registros del conjunto de prueba con una precisiÃ³n del 62%, por encima de la media. Los apoyos son bastante iguales (distribuciÃ³n uniforme de las clases en el conjunto de datos), por lo que la F1 ponderada y la F1 no ponderada van a ser aproximadamente iguales. TambiÃ©n podemos ver el resultado de las mÃ©tricas para cada una de las 4 clases. A partir de ahÃ­, podemos observar que la clase 2 tiene la precisiÃ³n, la recuperaciÃ³n y la puntuaciÃ³n f1 mÃ¡s bajas. La clase 3 estÃ¡ justo detrÃ¡s de la clase 2 por tener las puntuaciones mÃ¡s bajas, y luego, tenemos la clase 1 con las mejores puntuaciones seguida de la clase 4.\n",
    "\n",
    "Observando la matriz de confusiÃ³n, podemos ver que\n",
    "\n",
    "- la clase 1 se confundiÃ³ mayoritariamente con la clase 2 en 238 casos\n",
    "- la clase 2 por la clase 1 en 256 entradas, y por la clase 3 en 260 casos\n",
    "- la clase 3 se confundiÃ³ mayoritariamente con la clase 2, en 374 entradas, y con la clase 4, en 193 casos\n",
    "- la clase 4 se clasificÃ³ errÃ³neamente como clase 3 en 339 entradas, y como clase 2 en 130 casos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ObsÃ©rvese tambiÃ©n que la diagonal muestra los valores positivos verdaderos; al observarla, es evidente que las clases 2 y 3 tienen los valores predichos menos correctos.\n",
    "\n",
    "Con esos resultados, podrÃ­amos profundizar en el anÃ¡lisis inspeccionÃ¡ndolos mÃ¡s a fondo para averiguar por quÃ© ha sucedido eso, y tambiÃ©n entender si 4 clases son la mejor manera de agrupar los datos. Tal vez los valores de las clases 2 y 3 estaban demasiado prÃ³ximos entre sÃ­, por lo que resultaba difÃ­cil distinguirlos. AdemÃ¡s del nÃºmero arbitrario de bins de datos, tambiÃ©n hay otro nÃºmero arbitrario que hemos elegido, el nÃºmero de K vecinos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'decision_function' from 'sklearn.inspection' (c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\inspection\\__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_26196/902022373.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcolors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mListedColormap\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdatasets\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minspection\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mdecision_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0msklearn\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mneighbors\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mNearestCentroid\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'decision_function' from 'sklearn.inspection' (c:\\ProgramData\\Anaconda3\\lib\\site-packages\\sklearn\\inspection\\__init__.py)"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from matplotlib.colors import ListedColormap\n",
    "from sklearn import datasets\n",
    "from sklearn.inspection import decision_function\n",
    "from sklearn.neighbors import NearestCentroid\n",
    "\n",
    "# Suponiendo que x es un dataframe de pandas\n",
    "x_2d = iris[[\"sepal_length\", \"petal_length\",\"sepal_width\",\"petal_width\"]].to_numpy()\n",
    "y = iris[\"sepal_width_S\"]\n",
    "\n",
    "# Ahora x_2d serÃ¡ un arreglo numpy bidimensional con las dos variables seleccionadas\n",
    "print(x_2d)\n",
    "\n",
    "# Create color maps\n",
    "cmap_light = ListedColormap([\"orange\", \"cyan\", \"cornflowerblue\"])\n",
    "cmap_bold = ListedColormap([\"darkorange\", \"c\", \"darkblue\"])\n",
    "\n",
    "for shrinkage in [None, 0.2]:  # Utiliza 'None' en lugar de 'none'\n",
    "    # Creamos una instancia del clasificador NearestCentroid y ajustamos los datos.\n",
    "    clf = NearestCentroid(shrink_threshold=shrinkage)\n",
    "    clf.fit(x_2d, y)\n",
    "    y_pred = clf.predict(x_2d)\n",
    "    print(shrinkage, np.mean(y == y_pred))\n",
    "\n",
    "    _, ax = plt.subplots()\n",
    "    decision_function.decision_boundary_display(\n",
    "        clf, x_2d, cmap=cmap_light, ax=ax, response_method=\"predict\"\n",
    "    )\n",
    "\n",
    "    # TambiÃ©n graficamos los puntos de entrenamiento\n",
    "    plt.scatter(\n",
    "        x_2d[:, 0], x_2d[:, 1], c=y, cmap=cmap_bold, edgecolor=\"k\", s=10\n",
    "    )\n",
    "    plt.title(\"ClasificaciÃ³n de 3 clases (shrink_threshold=%r)\" % shrinkage)\n",
    "    plt.axis(\"tight\")\n",
    "    plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Finding the Best K for KNN Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Repitamos lo que se ha hecho para la regresiÃ³n y tracemos el grÃ¡fico de los valores de K y la mÃ©trica correspondiente para el conjunto de prueba. TambiÃ©n puede elegir la mÃ©trica que mejor se adapte a su contexto; en este caso, elegiremos la puntuaciÃ³n f1.\n",
    "\n",
    "De este modo, trazaremos la puntuaciÃ³n f1 para los valores predichos del conjunto de prueba para todos los valores de K comprendidos entre 1 y 40.\n",
    "\n",
    "En primer lugar, importamos f1_score de sklearn.metrics y, a continuaciÃ³n, calculamos su valor para todas las predicciones de un clasificador K-Nearest Neighbors, donde K oscila entre 1 y 40:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score\n",
    "\n",
    "f1s = []\n",
    "\n",
    "# Calculating f1 score for K values between 1 and 40\n",
    "for i in range(1, 40):\n",
    "    knn = KNeighborsClassifier(n_neighbors=i)\n",
    "    knn.fit(X_train, y_train)\n",
    "    pred_i = knn.predict(X_test)\n",
    "    # using average='weighted' to calculate a weighted average for the 4 classes \n",
    "    f1s.append(f1_score(y_test, pred_i, average='weighted'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El siguiente paso consiste en representar grÃ¡ficamente los valores de f1_score frente a los valores de K. La diferencia con la regresiÃ³n es que en lugar de elegir el valor K que minimiza el error, esta vez elegiremos el valor que maximiza la puntuaciÃ³n f1.\n",
    "\n",
    "Ejecute el siguiente script para crear el grÃ¡fico:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(range(1, 40), f1s, color='red', linestyle='dashed', marker='o', markerfacecolor='blue', markersize=10)\n",
    "plt.title('F1 Score K Value')\n",
    "plt.xlabel('K Value')\n",
    "plt.ylabel('F1 Score')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A partir de la salida, podemos ver que la puntuaciÃ³n f1 es la mÃ¡s alta cuando el valor de K es 15. Vamos a volver a entrenar nuestro clasificador con 15 vecinos y ver lo que hace a nuestros resultados del informe de clasificaciÃ³n:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier15 = KNeighborsClassifier(n_neighbors=15)\n",
    "classifier15.fit(X_train, y_train)\n",
    "y_pred15 = classifier15.predict(X_test)\n",
    "print(classification_report(y_test, y_pred15))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que nuestras mÃ©tricas han mejorado con 15 vecinos, tenemos un 63% de exactitud y mayores puntuaciones de precisiÃ³n, recuperaciÃ³n y f1, pero aÃºn tenemos que examinar mÃ¡s a fondo los bloques para intentar entender por quÃ© la puntuaciÃ³n f1 de las clases 2 y 3 sigue siendo baja.\n",
    "\n",
    "AdemÃ¡s de utilizar KNN para la regresiÃ³n y determinar los valores de los bloques y para la clasificaciÃ³n, para determinar las clases de los bloques, tambiÃ©n podemos utilizar KNN para detectar quÃ© valores medios de los bloques son diferentes de la mayorÃ­a, los que no siguen lo que hace la mayorÃ­a de los datos. En otras palabras, podemos utilizar KNN para detectar valores atÃ­picos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementando KNN para detecciÃ³n de datos atipicos con Scikit-Learn\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La detecciÃ³n de valores atÃ­picos utiliza otro mÃ©todo que difiere de lo que habÃ­amos hecho anteriormente para la regresiÃ³n y la clasificaciÃ³n.\n",
    "\n",
    "AquÃ­ veremos a quÃ© distancia se encuentra cada uno de los vecinos de un punto de datos. Utilizaremos los 5 vecinos por defecto. Para un punto de datos, calcularemos la distancia a cada uno de los K vecinos mÃ¡s cercanos. Para ello, importaremos otro algoritmo KNN de Scikit-learn que no es especÃ­fico ni para regresiÃ³n ni para clasificaciÃ³n llamado simplemente NearestNeighbors.\n",
    "\n",
    "DespuÃ©s de la importaciÃ³n, instanciaremos una clase NearestNeighbors con 5 vecinos - tambiÃ©n se puede instanciar con 12 vecinos para identificar valores atÃ­picos en nuestro ejemplo de regresiÃ³n o con 15, para hacer lo mismo para el ejemplo de clasificaciÃ³n. A continuaciÃ³n, ajustaremos nuestros datos de entrenamiento y utilizaremos el mÃ©todo kneighbors() para encontrar nuestras distancias calculadas para cada punto de datos e Ã­ndices de vecinos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import NearestNeighbors\n",
    "\n",
    "nbrs = NearestNeighbors(n_neighbors = 5)\n",
    "nbrs.fit(X_train)\n",
    "# Distances and indexes of the 5 neighbors \n",
    "distances, indexes = nbrs.kneighbors(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos 5 distancias para cada punto de datos: la distancia entre Ã©l y sus 5 vecinos, y un Ã­ndice que los identifica. Echemos un vistazo a los tres primeros resultados y a la forma del array para visualizarlo mejor.\n",
    "\n",
    "Para ver la forma de las tres primeras distancias, ejecuta:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "distances[:3], distances.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que hay 3 filas con 5 distancias cada una. TambiÃ©n podemos mirar y los Ã­ndices de los vecinos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "indexes[:3], indexes[:3].shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En la salida anterior, podemos ver los Ã­ndices de cada uno de los 5 vecinos. Ahora, podemos seguir calculando la media de las 5 distancias y trazar un grÃ¡fico que cuente cada fila en el eje X y muestre cada distancia media en el eje Y:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_means = distances.mean(axis=1)\n",
    "plt.plot(dist_means)\n",
    "plt.title('Mean of the 5 neighbors distances for each data point')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Mean Distances')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe que hay una parte del grÃ¡fico en la que las distancias medias tienen valores uniformes. Ese punto del eje Y en el que las medias no son ni demasiado altas ni demasiado bajas es exactamente el punto que necesitamos identificar para cortar los valores atÃ­picos.\n",
    "\n",
    "En este caso, es donde la distancia media es 3. Vamos a trazar de nuevo el grÃ¡fico con una lÃ­nea de puntos horizontal para poder identificarlo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dist_means = distances.mean(axis=1)\n",
    "plt.plot(dist_means)\n",
    "plt.title('Mean of the 5 neighbors distances for each data point with cut-off line')\n",
    "plt.xlabel('Count')\n",
    "plt.ylabel('Mean Distances')\n",
    "plt.axhline(y = 3, color = 'r', linestyle = '--')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Esta lÃ­nea marca la distancia media por encima de la cual varÃ­an todos los valores. Esto significa que todos los puntos con una distancia media superior a 3 son nuestros valores atÃ­picos. Podemos averiguar los Ã­ndices de esos puntos utilizando np.where(). Este mÃ©todo darÃ¡ como resultado Verdadero o Falso para cada Ã­ndice con respecto a la condiciÃ³n de media superior a 3:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Visually determine cutoff values > 3\n",
    "outlier_index = np.where(dist_means > 3)\n",
    "outlier_index\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora tenemos nuestros Ã­ndices de puntos atÃ­picos. Vamos a localizarlos en el marco de datos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter outlier values\n",
    "outlier_values = df.iloc[outlier_index]\n",
    "outlier_values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "AsÃ­ es como detectamos cada punto de datos que se desvÃ­a de la tendencia general de los datos. Podemos ver que hay 16 puntos en los datos de entrenamiento que deberÃ­an examinarse mÃ¡s a fondo, investigarse, tal vez tratarse o incluso eliminarse de nuestros datos (si se introdujeron errÃ³neamente) para mejorar los resultados. Estos puntos pueden deberse a errores tipogrÃ¡ficos, a incoherencias en los valores medios de los bloques, o incluso a ambas cosas."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.11.5 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "c261aea317cc0286b3b3261fbba9abdec21eaa57589985bb7a274bf54d6cc0a7"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
